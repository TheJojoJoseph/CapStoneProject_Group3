{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Data Transformation for Machine Learning and Analytics\n",
    "This notebook focuses on preparing the Airbnb dataset for advanced analytics and machine learning by performing **complex data transformations**, **feature engineering**, and **data normalization/encoding**.\n",
    "\n",
    "### Goals:\n",
    "1. **Complex Data Transformation Workflows**: Aggregate, filter, and enrich data to prepare for advanced analytics.\n",
    "2. **Feature Engineering**: Extract meaningful features (temporal and textual) to improve model performance.\n",
    "3. **Advanced Data Normalization and Encoding**: Prepare data for machine learning by scaling and encoding features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23918082 entries, 0 to 23918081\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   listing_id                   int64  \n",
      " 1   scrape_id                    int64  \n",
      " 2   name                         object \n",
      " 3   host_id                      int64  \n",
      " 4   host_name                    object \n",
      " 5   host_since                   object \n",
      " 6   host_location                object \n",
      " 7   latitude                     float64\n",
      " 8   longitude                    float64\n",
      " 9   neighbourhood_cleansed       object \n",
      " 10  city                         object \n",
      " 11  state                        object \n",
      " 12  country                      object \n",
      " 13  property_type                object \n",
      " 14  room_type                    object \n",
      " 15  accommodates                 int64  \n",
      " 16  bathrooms                    float64\n",
      " 17  bedrooms                     float64\n",
      " 18  beds                         float64\n",
      " 19  price_y                      float64\n",
      " 20  review_scores_rating         float64\n",
      " 21  review_scores_accuracy       float64\n",
      " 22  review_scores_cleanliness    float64\n",
      " 23  review_scores_checkin        float64\n",
      " 24  review_scores_communication  float64\n",
      " 25  review_scores_location       float64\n",
      " 26  review_scores_value          float64\n",
      " 27  reviews_per_month            float64\n",
      " 28  number_of_reviews            int64  \n",
      " 29  first_review                 object \n",
      " 30  last_review                  object \n",
      " 31  available                    int64  \n",
      " 32  price_x                      float64\n",
      " 33  availability_30              int64  \n",
      " 34  availability_60              int64  \n",
      " 35  availability_90              int64  \n",
      " 36  availability_365             int64  \n",
      "dtypes: float64(15), int64(10), object(12)\n",
      "memory usage: 6.6+ GB\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/dataset/final_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Data Loaded Successfully!\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement 6: Complex Data Transformation Workflows\n",
    "\n",
    "### Objective:\n",
    "Transform the data to meet business requirements and enable advanced analytics. This involves:\n",
    "1. **Aggregation**: Summarize data to identify trends and patterns.\n",
    "2. **Filtering**: Clean the dataset by removing irrelevant or redundant rows and columns.\n",
    "3. **Enrichment**: Create new derived features to enhance the dataset's value for analysis.\n",
    "\n",
    "### What We Are Doing and Why:\n",
    "1. **Aggregation**:\n",
    "   - Aggregating `price_y`, `number_of_reviews`, and `reviews_per_month` by `neighbourhood_cleansed` provides insights into average prices, total reviews, and activity by neighborhood.\n",
    "   - This helps identify high-performing neighborhoods for targeted analysis.\n",
    "\n",
    "2. **Filtering**:\n",
    "   - Filtering rows where `price_y` is greater than 0 and `availability_365` is greater than 0 ensures we focus on valid and active listings.\n",
    "   - Adding a `revenue` column (`price_y` × `availability_365`) quantifies each listing's potential earnings.\n",
    "   - Classifying revenue into \"Low,\" \"Medium,\" and \"High\" categories enables segmentation analysis.\n",
    "\n",
    "3. **Enrichment**:\n",
    "   - **`price_per_bedroom`**: Normalizes price by the number of bedrooms for fairer comparisons.\n",
    "   - **`review_count_score`**: Combines `number_of_reviews` and `review_scores_rating` to rank listings based on popularity and quality.\n",
    "   - **`is_recent_review`**: Identifies listings with reviews in the past year for recency-based analysis.\n",
    "\n",
    "These transformations make the dataset more actionable for analysis and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>avg_reviews_per_month</th>\n",
       "      <th>avg_availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams</td>\n",
       "      <td>122.849728</td>\n",
       "      <td>66551910</td>\n",
       "      <td>4.121451</td>\n",
       "      <td>282.171341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alki</td>\n",
       "      <td>145.676580</td>\n",
       "      <td>9330495</td>\n",
       "      <td>2.698397</td>\n",
       "      <td>292.831560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbor Heights</td>\n",
       "      <td>168.486319</td>\n",
       "      <td>364270</td>\n",
       "      <td>0.942455</td>\n",
       "      <td>278.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlantic</td>\n",
       "      <td>118.705948</td>\n",
       "      <td>33995370</td>\n",
       "      <td>4.424540</td>\n",
       "      <td>243.608844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belltown</td>\n",
       "      <td>154.828553</td>\n",
       "      <td>121058820</td>\n",
       "      <td>3.824602</td>\n",
       "      <td>239.967988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_cleansed   avg_price  total_reviews  avg_reviews_per_month  \\\n",
       "0                  Adams  122.849728       66551910               4.121451   \n",
       "1                   Alki  145.676580        9330495               2.698397   \n",
       "2          Arbor Heights  168.486319         364270               0.942455   \n",
       "3               Atlantic  118.705948       33995370               4.424540   \n",
       "4               Belltown  154.828553      121058820               3.824602   \n",
       "\n",
       "   avg_availability_365  \n",
       "0            282.171341  \n",
       "1            292.831560  \n",
       "2            278.083333  \n",
       "3            243.608844  \n",
       "4            239.967988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregation\n",
    "aggregated_data = data.groupby('neighbourhood_cleansed').agg({\n",
    "    'price_y': 'mean',\n",
    "    'number_of_reviews': 'sum',\n",
    "    'reviews_per_month': 'mean',\n",
    "    'availability_365': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "aggregated_data.rename(columns={\n",
    "    'price_y': 'avg_price',\n",
    "    'number_of_reviews': 'total_reviews',\n",
    "    'reviews_per_month': 'avg_reviews_per_month',\n",
    "    'availability_365': 'avg_availability_365'\n",
    "}, inplace=True)\n",
    "print(\"Aggregated Data:\")\n",
    "display(aggregated_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Shape: (23638940, 37)\n"
     ]
    }
   ],
   "source": [
    "# Filtering\n",
    "filtered_data = data[(data['price_y'] > 0) & (data['availability_365'] > 0)]\n",
    "print(f\"Filtered Data Shape: {filtered_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       revenue revenue_category\n",
      "0  29410.00000             High\n",
      "1  29410.00000             High\n",
      "2  48597.59954             High\n",
      "3  48597.59954             High\n",
      "4  48597.59954             High\n"
     ]
    }
   ],
   "source": [
    "# Add a revenue column (price * availability_365)\n",
    "filtered_data[\"revenue\"] = filtered_data[\"price_y\"] * filtered_data[\"availability_365\"]\n",
    "\n",
    "# Add a column to classify properties as high, medium, or low revenue\n",
    "filtered_data[\"revenue_category\"] = pd.cut(\n",
    "    filtered_data[\"revenue\"],\n",
    "    bins=[0, 5000, 20000, np.inf],\n",
    "    labels=[\"Low\", \"Medium\", \"High\"]\n",
    ")\n",
    "\n",
    "print(filtered_data[[\"revenue\", \"revenue_category\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Enrichment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_per_bedroom</th>\n",
       "      <th>review_count_score</th>\n",
       "      <th>is_recent_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.00000</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.00000</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.45549</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140.45549</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.45549</td>\n",
       "      <td>19665.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_per_bedroom  review_count_score  is_recent_review\n",
       "0           85.00000             19665.0             False\n",
       "1           85.00000             19665.0             False\n",
       "2          140.45549             19665.0             False\n",
       "3          140.45549             19665.0             False\n",
       "4          140.45549             19665.0             False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enrichment\n",
    "data['price_per_bedroom'] = np.where(data['bedrooms'] > 0, data['price_y'] / data['bedrooms'], 0)\n",
    "data['review_count_score'] = data['number_of_reviews'] * data['review_scores_rating']\n",
    "data['is_recent_review'] = pd.to_datetime(data['last_review'], errors='coerce').apply(\n",
    "    lambda x: x >= datetime.now() - pd.DateOffset(years=1) if pd.notnull(x) else False)\n",
    "\n",
    "print(\"Data after Enrichment:\")\n",
    "display(data[['price_per_bedroom', 'review_count_score', 'is_recent_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement 7: Feature Engineering for Machine Learning\n",
    "\n",
    "### Objective:\n",
    "Extract meaningful features that enhance machine learning model performance. This involves:\n",
    "1. **Temporal Features**: Extract time-based features from review and hosting data to capture trends and patterns.\n",
    "2. **Textual Features**: Use Natural Language Processing (NLP) techniques to extract insights from text data.\n",
    "\n",
    "### What We Are Doing and Why:\n",
    "1. **Temporal Features**:\n",
    "   - Extracting features such as `last_review_year`, `last_review_month`, and `last_review_dayofweek` from `last_review` enables time-based analysis.\n",
    "   - Temporal features like `days_since_last_review` and `host_duration_days` provide critical context for modeling activity over time.\n",
    "\n",
    "2. **Textual Features (TF-IDF)**:\n",
    "   - Using `TfidfVectorizer` to convert the `name` column into numerical features captures textual patterns in the listing names.\n",
    "   - By precomputing a global vocabulary, we ensure consistency across batches, preventing column mismatches.\n",
    "\n",
    "These features enhance the dataset’s richness, making it suitable for both predictive and descriptive analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Features Extracted:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_review_year</th>\n",
       "      <th>last_review_month</th>\n",
       "      <th>last_review_dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_review_year  last_review_month  last_review_dayofweek\n",
       "0              2016                  1                      5\n",
       "1              2016                  1                      5\n",
       "2              2016                  1                      5\n",
       "3              2016                  1                      5\n",
       "4              2016                  1                      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temporal Features\n",
    "data['last_review_date'] = pd.to_datetime(data['last_review'], errors='coerce')\n",
    "data['last_review_year'] = data['last_review_date'].dt.year\n",
    "data['last_review_month'] = data['last_review_date'].dt.month\n",
    "data['last_review_dayofweek'] = data['last_review_date'].dt.dayofweek\n",
    "\n",
    "print(\"Temporal Features Extracted:\")\n",
    "display(data[['last_review_year', 'last_review_month', 'last_review_dayofweek']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global vocabulary created with 50 features.\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'name'\n",
    "data['name'] = data['name'].fillna('unknown')\n",
    "\n",
    "# Fit the vectorizer on the entire 'name' column\n",
    "vectorizer = TfidfVectorizer(max_features=50, stop_words='english')  # Adjust max_features as needed\n",
    "vectorizer.fit(data['name'].astype(str))  # Pre-fit on all data\n",
    "\n",
    "# Extract the global vocabulary\n",
    "global_vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Global vocabulary created with {len(global_vocab)} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing and merging batches: 100%|██████████| 23919/23919 [12:25<00:00, 32.07batch/s]   \n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 1000\n",
    "output_file = '/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/dataset/final_data_with_tfidf.csv'\n",
    "\n",
    "# Initialize the output file\n",
    "pd.DataFrame().to_csv(output_file, index=False)  # Create an empty file\n",
    "\n",
    "# Process data in batches\n",
    "for start in tqdm(range(0, len(data), batch_size), desc=\"Processing and merging batches\", unit=\"batch\"):\n",
    "    # Select the current batch\n",
    "    batch = data.iloc[start:start + batch_size].copy()\n",
    "    \n",
    "    # Fill missing values in 'name'\n",
    "    batch['name'] = batch['name'].fillna('unknown')\n",
    "\n",
    "    # Use the pre-fitted vectorizer with the global vocabulary\n",
    "    tfidf_matrix = vectorizer.transform(batch['name'].astype(str))  # Use .transform, not .fit_transform\n",
    "\n",
    "    # Convert TF-IDF matrix to DataFrame\n",
    "    tfidf_batch_df = pd.DataFrame(tfidf_matrix.toarray(), columns=global_vocab)\n",
    "\n",
    "    # Merge TF-IDF features with the current batch\n",
    "    merged_batch = pd.concat([batch.reset_index(drop=True), tfidf_batch_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Append the merged batch to the output file\n",
    "    merged_batch.to_csv(output_file, mode='a', header=not bool(start), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   listing_id       scrape_id                          name  host_id  \\\n",
      "0      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
      "1      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
      "2      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
      "3      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
      "4      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
      "\n",
      "  host_name  host_since                       host_location   latitude  \\\n",
      "0     Maija  2011-08-11  Seattle, Washington, United States  47.636289   \n",
      "1     Maija  2011-08-11  Seattle, Washington, United States  47.636289   \n",
      "2     Maija  2011-08-11  Seattle, Washington, United States  47.636289   \n",
      "3     Maija  2011-08-11  Seattle, Washington, United States  47.636289   \n",
      "4     Maija  2011-08-11  Seattle, Washington, United States  47.636289   \n",
      "\n",
      "    longitude neighbourhood_cleansed  ... room seattle spacious studio suite  \\\n",
      "0 -122.371025        West Queen Anne  ...  0.0     0.0      0.0    0.0   0.0   \n",
      "1 -122.371025        West Queen Anne  ...  0.0     0.0      0.0    0.0   0.0   \n",
      "2 -122.371025        West Queen Anne  ...  0.0     0.0      0.0    0.0   0.0   \n",
      "3 -122.371025        West Queen Anne  ...  0.0     0.0      0.0    0.0   0.0   \n",
      "4 -122.371025        West Queen Anne  ...  0.0     0.0      0.0    0.0   0.0   \n",
      "\n",
      "   urban   uw  view  views  west  \n",
      "0    0.0  0.0   0.0    0.0   0.0  \n",
      "1    0.0  0.0   0.0    0.0   0.0  \n",
      "2    0.0  0.0   0.0    0.0   0.0  \n",
      "3    0.0  0.0   0.0    0.0   0.0  \n",
      "4    0.0  0.0   0.0    0.0   0.0  \n",
      "\n",
      "[5 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load a sample from the saved file\n",
    "result = pd.read_csv(\"output_file\", nrows=5)\n",
    "print(result.head())\n",
    "\n",
    "result = pd.read_csv(output_file)\n",
    "print(f\"Total rows: {len(result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   host_duration_days  days_since_last_review  days_between_reviews\n",
      "0                4875                    3270                  1523\n",
      "1                4875                    3270                  1523\n",
      "2                4875                    3270                  1523\n",
      "3                4875                    3270                  1523\n",
      "4                4875                    3270                  1523\n"
     ]
    }
   ],
   "source": [
    "# Convert dates to datetime format\n",
    "data[\"host_since\"] = pd.to_datetime(data[\"host_since\"])\n",
    "data[\"first_review\"] = pd.to_datetime(data[\"first_review\"])\n",
    "data[\"last_review\"] = pd.to_datetime(data[\"last_review\"])\n",
    "\n",
    "# Create new temporal features\n",
    "data[\"host_duration_days\"] = (pd.Timestamp.now() - data[\"host_since\"]).dt.days\n",
    "data[\"days_since_last_review\"] = (pd.Timestamp.now() - data[\"last_review\"]).dt.days\n",
    "data[\"days_between_reviews\"] = (data[\"last_review\"] - data[\"first_review\"]).dt.days\n",
    "\n",
    "print(data[[\"host_duration_days\", \"days_since_last_review\", \"days_between_reviews\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement 8: Advanced Data Normalization and Encoding\n",
    "\n",
    "### Objective:\n",
    "Prepare the dataset for machine learning by:\n",
    "1. **Normalizing numerical features** to ensure scale consistency.\n",
    "2. **Encoding categorical features** to convert them into machine-readable formats.\n",
    "\n",
    "### What We Are Doing and Why:\n",
    "1. **Normalization**:\n",
    "   - Applying Min-Max Scaling to columns like `price_y`, `review_scores_rating`, and `number_of_reviews` ensures numerical features are on a comparable scale.\n",
    "   - This prevents features with larger ranges from dominating the model during training.\n",
    "\n",
    "2. **Encoding**:\n",
    "   - **One-Hot Encoding**: Converts categorical variables like `room_type` and `property_type` into binary columns. This is essential for models that cannot handle categorical data directly.\n",
    "   - **Label Encoding**: Encodes binary features like `is_recent_review` into numerical values (0 or 1).\n",
    "\n",
    "These steps ensure the dataset is ready for machine learning algorithms that require normalized and encoded inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_y</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079546</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079546</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079546</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price_y  review_scores_rating  number_of_reviews  availability_365\n",
       "0  0.045732                0.9375           0.436709          0.947945\n",
       "1  0.045732                0.9375           0.436709          0.947945\n",
       "2  0.079546                0.9375           0.436709          0.947945\n",
       "3  0.079546                0.9375           0.436709          0.947945\n",
       "4  0.079546                0.9375           0.436709          0.947945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "numerical_cols = ['price_y', 'review_scores_rating', 'number_of_reviews', 'availability_365']\n",
    "normalized_data = pd.DataFrame(scaler.fit_transform(data[numerical_cols]), columns=numerical_cols)\n",
    "print(\"Normalized Data:\")\n",
    "display(normalized_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Chalet</th>\n",
       "      <th>property_type_Condominium</th>\n",
       "      <th>property_type_Dorm</th>\n",
       "      <th>property_type_House</th>\n",
       "      <th>property_type_Loft</th>\n",
       "      <th>property_type_Other</th>\n",
       "      <th>property_type_Tent</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Yurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>956883</td>\n",
       "      <td>Maija</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>47.636289</td>\n",
       "      <td>-122.371025</td>\n",
       "      <td>West Queen Anne</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>956883</td>\n",
       "      <td>Maija</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>47.636289</td>\n",
       "      <td>-122.371025</td>\n",
       "      <td>West Queen Anne</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>956883</td>\n",
       "      <td>Maija</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>47.636289</td>\n",
       "      <td>-122.371025</td>\n",
       "      <td>West Queen Anne</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>956883</td>\n",
       "      <td>Maija</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>47.636289</td>\n",
       "      <td>-122.371025</td>\n",
       "      <td>West Queen Anne</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>956883</td>\n",
       "      <td>Maija</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>Seattle, Washington, United States</td>\n",
       "      <td>47.636289</td>\n",
       "      <td>-122.371025</td>\n",
       "      <td>West Queen Anne</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       scrape_id                          name  host_id  \\\n",
       "0      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
       "1      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
       "2      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
       "3      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
       "4      241032  20160104002432  Stylish Queen Anne Apartment   956883   \n",
       "\n",
       "  host_name host_since                       host_location   latitude  \\\n",
       "0     Maija 2011-08-11  Seattle, Washington, United States  47.636289   \n",
       "1     Maija 2011-08-11  Seattle, Washington, United States  47.636289   \n",
       "2     Maija 2011-08-11  Seattle, Washington, United States  47.636289   \n",
       "3     Maija 2011-08-11  Seattle, Washington, United States  47.636289   \n",
       "4     Maija 2011-08-11  Seattle, Washington, United States  47.636289   \n",
       "\n",
       "    longitude neighbourhood_cleansed  ... property_type_Chalet  \\\n",
       "0 -122.371025        West Queen Anne  ...                    0   \n",
       "1 -122.371025        West Queen Anne  ...                    0   \n",
       "2 -122.371025        West Queen Anne  ...                    0   \n",
       "3 -122.371025        West Queen Anne  ...                    0   \n",
       "4 -122.371025        West Queen Anne  ...                    0   \n",
       "\n",
       "  property_type_Condominium property_type_Dorm  property_type_House  \\\n",
       "0                         0                  0                    0   \n",
       "1                         0                  0                    0   \n",
       "2                         0                  0                    0   \n",
       "3                         0                  0                    0   \n",
       "4                         0                  0                    0   \n",
       "\n",
       "   property_type_Loft  property_type_Other  property_type_Tent  \\\n",
       "0                   0                    0                   0   \n",
       "1                   0                    0                   0   \n",
       "2                   0                    0                   0   \n",
       "3                   0                    0                   0   \n",
       "4                   0                    0                   0   \n",
       "\n",
       "   property_type_Townhouse  property_type_Treehouse  property_type_Yurt  \n",
       "0                        0                        0                   0  \n",
       "1                        0                        0                   0  \n",
       "2                        0                        0                   0  \n",
       "3                        0                        0                   0  \n",
       "4                        0                        0                   0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "# One-Hot Encoding\n",
    "encoded_data = pd.get_dummies(data, columns=['room_type', 'property_type'], drop_first=True)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_data['is_recent_review'] = label_encoder.fit_transform(data['is_recent_review'])\n",
    "\n",
    "print(\"Encoded Data:\")\n",
    "display(encoded_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

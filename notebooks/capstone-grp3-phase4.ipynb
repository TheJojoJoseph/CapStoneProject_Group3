{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from google.cloud import bigquery, storage\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Data Warehouse Schema\n",
    "A recommended approach is to break down final_data into dimension and fact tables. For example:\n",
    "\n",
    "- Fact Table: fact_listings\n",
    "\n",
    "Contains keys referencing dimension tables.\n",
    "Contains metrics such as price_y, availability_365, number_of_reviews, revenue (derived).\n",
    "\n",
    "- Dimension Tables:\n",
    "\n",
    "dim_host: Information about hosts (host_id, host_name, host_since, host_location).\n",
    "dim_geography: Information about location (neighbourhood_cleansed, city, state, country, latitude, longitude).\n",
    "dim_property: Information about listings (property_type, room_type, accommodates, bedrooms, beds).\n",
    "dim_date: A date dimension for first_review, last_review.\n",
    "Note: If you have all data in one table, you can create views or separate tables to follow a star schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the final_data into dimension and fact tables locally, then upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv(\"/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/dataset/final_data_with_tfidf.csv\")\n",
    "\n",
    "# Dimension: dim_host\n",
    "dim_host = final_data[['host_id', 'host_name', 'host_since', 'host_location']]\n",
    "\n",
    "# Dimension: dim_geography\n",
    "dim_geography = final_data[['listing_id', 'neighbourhood_cleansed', 'city', 'state', 'country', 'latitude', 'longitude']]\n",
    "\n",
    "# Dimension: dim_property\n",
    "dim_property = final_data[['listing_id', 'property_type', 'room_type', 'accommodates', 'bedrooms', 'beds']]\n",
    "\n",
    "# Dimension: dim_date (we'll focus on last_review as a primary date field)\n",
    "dim_date = final_data[['listing_id', 'last_review']]\n",
    "\n",
    "dim_date['last_review'] = pd.to_datetime(dim_date['last_review'])\n",
    "dim_date['review_year'] = dim_date['last_review'].dt.year\n",
    "dim_date['review_month'] = dim_date['last_review'].dt.month\n",
    "dim_date['review_day'] = dim_date['last_review'].dt.day\n",
    "\n",
    "# Fact Table: fact_listings\n",
    "fact_listings = final_data[['listing_id', 'host_id', 'price_y', 'number_of_reviews', 'reviews_per_month', 'availability_365']]\n",
    "\n",
    "dim_host.to_csv(\"dim_host.csv\", index=False)\n",
    "dim_geography.to_csv(\"dim_geography.csv\", index=False)\n",
    "dim_property.to_csv(\"dim_property.csv\", index=False)\n",
    "dim_date.to_csv(\"dim_date.csv\", index=False)\n",
    "fact_listings.to_csv(\"fact_listings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a star schema in BigQuery.\n",
    "\n",
    "- Use a star schema for simplicity:\n",
    "\n",
    "- Fact Table:\n",
    "    fact_listings: Contains metrics like price, availability, and reviews.\n",
    "- Dimension Tables:\n",
    "    dim_hosts: Contains host-specific details.\n",
    "    dim_properties: Contains property-related details like room_type, property_type, and neighbourhood.\n",
    "    dim_reviews: Contains details of reviews such as review scores and dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload these CSVs to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/capstoneproject-444019-7bad7df402b1.json\"\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(\"airbnb-data-ingestion\")\n",
    "\n",
    "for file_name in [\"dim_host.csv\", \"dim_geography.csv\", \"dim_property.csv\", \"dim_date.csv\", \"fact_listings.csv\"]:\n",
    "    blob = bucket.blob(f\"airbnb/{file_name}\")\n",
    "    blob.upload_from_filename(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load these into BigQuery as separate tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define dataset name\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dataset_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapstoneproject-444019.airbnb_dim_tables\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/client.py:243\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, location, default_query_job_config, default_load_job_config, client_info, client_options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    242\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Client, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    244\u001b[0m         project\u001b[38;5;241m=\u001b[39mproject,\n\u001b[1;32m    245\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m    246\u001b[0m         client_options\u001b[38;5;241m=\u001b[39mclient_options,\n\u001b[1;32m    247\u001b[0m         _http\u001b[38;5;241m=\u001b[39m_http,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m     kw_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: client_info}\n\u001b[1;32m    251\u001b[0m     bq_host \u001b[38;5;241m=\u001b[39m _get_bigquery_host()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _http\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, project\u001b[38;5;241m=\u001b[39mproject, credentials\u001b[38;5;241m=\u001b[39mcredentials)\n\u001b[1;32m    321\u001b[0m     Client\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m, credentials\u001b[38;5;241m=\u001b[39mcredentials, client_options\u001b[38;5;241m=\u001b[39mclient_options, _http\u001b[38;5;241m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_default(project)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject was not passed and could not be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetermined from the environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault()\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/auth/_default.py:697\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    689\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    694\u001b[0m             )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 697\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "dataset_id = \"airbnb_dataset\"\n",
    "\n",
    "def load_csv_to_bq(table_name, schema, uri):\n",
    "    table_id = f\"{bq_client.project}.{dataset_id}.{table_name}\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=schema,\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "    )\n",
    "\n",
    "    load_job = bq_client.load_table_from_uri(uri, table_id, job_config=job_config)\n",
    "    load_job.result()\n",
    "    print(f\"Loaded {table_name}.\")\n",
    "\n",
    "# Define schemas\n",
    "dim_host_schema = [\n",
    "    bigquery.SchemaField(\"host_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"host_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"host_since\", \"DATE\"),\n",
    "    bigquery.SchemaField(\"host_location\", \"STRING\")\n",
    "]\n",
    "\n",
    "dim_geography_schema = [\n",
    "    bigquery.SchemaField(\"listing_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"neighbourhood_cleansed\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"city\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"state\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"country\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"latitude\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"longitude\", \"FLOAT\")\n",
    "]\n",
    "\n",
    "dim_property_schema = [\n",
    "    bigquery.SchemaField(\"listing_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"property_type\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"room_type\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"accommodates\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"bedrooms\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"beds\", \"FLOAT\")\n",
    "]\n",
    "\n",
    "dim_date_schema = [\n",
    "    bigquery.SchemaField(\"listing_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"last_review\", \"DATE\"),\n",
    "    bigquery.SchemaField(\"review_year\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"review_month\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"review_day\", \"INTEGER\")\n",
    "]\n",
    "\n",
    "fact_listings_schema = [\n",
    "    bigquery.SchemaField(\"listing_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"host_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"price_y\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"number_of_reviews\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"reviews_per_month\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"availability_365\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"revenue\", \"FLOAT\")\n",
    "]\n",
    "\n",
    "load_csv_to_bq(\"dim_host\", dim_host_schema, \"gs://airbnb-data-ingestion/airbnb/dim_host.csv\")\n",
    "load_csv_to_bq(\"dim_geography\", dim_geography_schema, \"gs://airbnb-data-ingestion/airbnb/dim_geography.csv\")\n",
    "load_csv_to_bq(\"dim_property\", dim_property_schema, \"gs://airbnb-data-ingestion/airbnb/dim_property.csv\")\n",
    "load_csv_to_bq(\"dim_date\", dim_date_schema, \"gs://airbnb-data-ingestion/airbnb/dim_date.csv\")\n",
    "load_csv_to_bq(\"fact_listings\", fact_listings_schema, \"gs://airbnb-data-ingestion/airbnb/fact_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. Cleaned data saved to '/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/notebooks/dim_date_no_duplicates.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = '/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/notebooks/dim_date.csv'  # Replace with your input CSV file path\n",
    "output_file = '/Users/asr/Desktop/College/CapstoneProject/CapStoneProject_Group3/notebooks/dim_date_no_duplicates.csv'  # Replace with your desired output CSV file path\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV\n",
    "df_cleaned.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Duplicates removed. Cleaned data saved to '{output_file}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
